{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/chris/OneDrive/Desktop/pleasegod/my-next-app/app/api/transcribe/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from \"next/server\";\r\nimport { OpenAI } from \"openai\";\r\n\r\nconst openai = new OpenAI({\r\n  apiKey: process.env.OPENAI_API_KEY,\r\n});\r\n\r\nexport async function POST(req: NextRequest) {\r\n  const data = await req.formData();\r\n  const file = data.get(\"file\") as Blob | null;\r\n\r\n  if (!file) {\r\n    return NextResponse.json({ error: \"No file uploaded\" }, { status: 400 });\r\n  }\r\n\r\n  // Convert Blob to File (OpenAI expects File type in Node)\r\n  const arrayBuffer = await file.arrayBuffer();\r\n  const nodeFile = new File([arrayBuffer], \"audio.mp3\", { type: \"audio/mpeg\" });\r\n\r\n  const transcription = await openai.audio.transcriptions.create({\r\n    file: nodeFile,\r\n    model: \"whisper-1\",\r\n  });\r\n\r\n  return NextResponse.json({ text: transcription.text });\r\n}\r\n"],"names":[],"mappings":";;;;AAAA;AACA;AAAA;;;AAEA,MAAM,SAAS,IAAI,6IAAM,CAAC;IACxB,QAAQ,QAAQ,GAAG,CAAC,cAAc;AACpC;AAEO,eAAe,KAAK,GAAgB;IACzC,MAAM,OAAO,MAAM,IAAI,QAAQ;IAC/B,MAAM,OAAO,KAAK,GAAG,CAAC;IAEtB,IAAI,CAAC,MAAM;QACT,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE,OAAO;QAAmB,GAAG;YAAE,QAAQ;QAAI;IACxE;IAEA,0DAA0D;IAC1D,MAAM,cAAc,MAAM,KAAK,WAAW;IAC1C,MAAM,WAAW,IAAI,KAAK;QAAC;KAAY,EAAE,aAAa;QAAE,MAAM;IAAa;IAE3E,MAAM,gBAAgB,MAAM,OAAO,KAAK,CAAC,cAAc,CAAC,MAAM,CAAC;QAC7D,MAAM;QACN,OAAO;IACT;IAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;QAAE,MAAM,cAAc,IAAI;IAAC;AACtD","debugId":null}}]
}